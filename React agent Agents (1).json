{
  "nodes": [
    {
      "id": "supervisor_0",
      "position": {
        "x": 217.3283180175107,
        "y": -92.34425913273378
      },
      "type": "customNode",
      "data": {
        "id": "supervisor_0",
        "label": "Supervisor",
        "version": 1,
        "name": "supervisor",
        "type": "Supervisor",
        "baseClasses": [
          "Supervisor"
        ],
        "category": "Multi Agents",
        "inputParams": [
          {
            "label": "Supervisor Name",
            "name": "supervisorName",
            "type": "string",
            "placeholder": "Supervisor",
            "default": "Supervisor",
            "id": "supervisor_0-input-supervisorName-string"
          },
          {
            "label": "Supervisor Prompt",
            "name": "supervisorPrompt",
            "type": "string",
            "description": "Prompt must contains {team_members}",
            "rows": 4,
            "default": "You are a supervisor tasked with managing a conversation between the following workers: {team_members}.\nGiven the following user request, respond with the worker to act next.\nEach worker will perform a task and respond with their results and status.\nWhen finished, respond with FINISH.\nSelect strategically to minimize the number of steps taken.",
            "additionalParams": true,
            "id": "supervisor_0-input-supervisorPrompt-string"
          },
          {
            "label": "Recursion Limit",
            "name": "recursionLimit",
            "type": "number",
            "description": "Maximum number of times a call can recurse. If not provided, defaults to 100.",
            "default": 100,
            "additionalParams": true,
            "id": "supervisor_0-input-recursionLimit-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Tool Calling Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, GroqChat. Best result with GPT-4 model",
            "id": "supervisor_0-input-model-BaseChatModel"
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "supervisor_0-input-inputModeration-Moderation"
          }
        ],
        "inputs": {
          "supervisorName": "Supervisor",
          "supervisorPrompt": "You are a supervisor tasked with managing a conversation between the following workers: {team_members}.\nGiven the following user request, respond with the worker to act next.\nEach worker will perform a task and respond with their results and status.\nWhen finished, respond with FINISH.\nSelect strategically to minimize the number of steps taken.",
          "model": "{{chatOpenAI_0.data.instance}}",
          "recursionLimit": 100,
          "inputModeration": ""
        },
        "outputAnchors": [
          {
            "id": "supervisor_0-output-supervisor-Supervisor",
            "name": "supervisor",
            "label": "Supervisor",
            "description": "",
            "type": "Supervisor"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 431,
      "selected": false,
      "positionAbsolute": {
        "x": 217.3283180175107,
        "y": -92.34425913273378
      },
      "dragging": false
    },
    {
      "id": "chatOpenAI_0",
      "position": {
        "x": -114.85319631876368,
        "y": 19.22319560448514
      },
      "type": "customNode",
      "data": {
        "id": "chatOpenAI_0",
        "label": "ChatOpenAI",
        "version": 6,
        "name": "chatOpenAI",
        "type": "ChatOpenAI",
        "baseClasses": [
          "ChatOpenAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "openAIApi"
            ],
            "id": "chatOpenAI_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gpt-3.5-turbo",
            "id": "chatOpenAI_0-input-modelName-asyncOptions"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatOpenAI_0-input-temperature-number"
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-maxTokens-number"
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-topP-number"
          },
          {
            "label": "Frequency Penalty",
            "name": "frequencyPenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-frequencyPenalty-number"
          },
          {
            "label": "Presence Penalty",
            "name": "presencePenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-presencePenalty-number"
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-timeout-number"
          },
          {
            "label": "BasePath",
            "name": "basepath",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-basepath-string"
          },
          {
            "label": "BaseOptions",
            "name": "baseOptions",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-baseOptions-json"
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Automatically uses gpt-4-vision-preview when image is being uploaded from chat. Only works with LLMChain, Conversation Chain, ReAct Agent, and Conversational Agent",
            "default": false,
            "optional": true,
            "id": "chatOpenAI_0-input-allowImageUploads-boolean"
          },
          {
            "label": "Image Resolution",
            "description": "This parameter controls the resolution in which the model views the image.",
            "name": "imageResolution",
            "type": "options",
            "options": [
              {
                "label": "Low",
                "name": "low"
              },
              {
                "label": "High",
                "name": "high"
              },
              {
                "label": "Auto",
                "name": "auto"
              }
            ],
            "default": "low",
            "optional": false,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-imageResolution-options"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatOpenAI_0-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "gpt-3.5-turbo",
          "temperature": "0",
          "maxTokens": "",
          "topP": "",
          "frequencyPenalty": "",
          "presencePenalty": "",
          "timeout": "",
          "basepath": "",
          "baseOptions": "",
          "allowImageUploads": "",
          "imageResolution": "low"
        },
        "outputAnchors": [
          {
            "id": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatOpenAI",
            "label": "ChatOpenAI",
            "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
            "type": "ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 669,
      "selected": false,
      "positionAbsolute": {
        "x": -114.85319631876368,
        "y": 19.22319560448514
      },
      "dragging": false
    },
    {
      "id": "worker_0",
      "position": {
        "x": 561.6741565090034,
        "y": 11.82113534534733
      },
      "type": "customNode",
      "data": {
        "id": "worker_0",
        "label": "Worker",
        "version": 1,
        "name": "worker",
        "type": "Worker",
        "baseClasses": [
          "Worker"
        ],
        "category": "Multi Agents",
        "inputParams": [
          {
            "label": "Worker Name",
            "name": "workerName",
            "type": "string",
            "placeholder": "Worker",
            "id": "worker_0-input-workerName-string"
          },
          {
            "label": "Worker Prompt",
            "name": "workerPrompt",
            "type": "string",
            "rows": 4,
            "default": "You are a research assistant who can search for up-to-date info using search engine.",
            "id": "worker_0-input-workerPrompt-string"
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "worker_0-input-promptValues-json"
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "id": "worker_0-input-maxIterations-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "optional": true,
            "id": "worker_0-input-tools-Tool"
          },
          {
            "label": "Supervisor",
            "name": "supervisor",
            "type": "Supervisor",
            "id": "worker_0-input-supervisor-Supervisor"
          },
          {
            "label": "Tool Calling Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "optional": true,
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat. If not specified, supervisor's model will be used",
            "id": "worker_0-input-model-BaseChatModel"
          }
        ],
        "inputs": {
          "workerName": "Time Teller",
          "workerPrompt": "You are a computer, You tell the current time and date in the format of \"%Y-%m-%d %H:%M:%S\"",
          "tools": "",
          "supervisor": "{{supervisor_0.data.instance}}",
          "model": "",
          "promptValues": "",
          "maxIterations": ""
        },
        "outputAnchors": [
          {
            "id": "worker_0-output-worker-Worker",
            "name": "worker",
            "label": "Worker",
            "description": "",
            "type": "Worker"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 808,
      "selected": false,
      "positionAbsolute": {
        "x": 561.6741565090034,
        "y": 11.82113534534733
      },
      "dragging": false
    },
    {
      "id": "worker_1",
      "position": {
        "x": 224.37483485842378,
        "y": 410.7461926048213
      },
      "type": "customNode",
      "data": {
        "id": "worker_1",
        "label": "Worker",
        "version": 1,
        "name": "worker",
        "type": "Worker",
        "baseClasses": [
          "Worker"
        ],
        "category": "Multi Agents",
        "inputParams": [
          {
            "label": "Worker Name",
            "name": "workerName",
            "type": "string",
            "placeholder": "Worker",
            "id": "worker_1-input-workerName-string"
          },
          {
            "label": "Worker Prompt",
            "name": "workerPrompt",
            "type": "string",
            "rows": 4,
            "default": "You are a research assistant who can search for up-to-date info using search engine.",
            "id": "worker_1-input-workerPrompt-string"
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "worker_1-input-promptValues-json"
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "id": "worker_1-input-maxIterations-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "optional": true,
            "id": "worker_1-input-tools-Tool"
          },
          {
            "label": "Supervisor",
            "name": "supervisor",
            "type": "Supervisor",
            "id": "worker_1-input-supervisor-Supervisor"
          },
          {
            "label": "Tool Calling Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "optional": true,
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat. If not specified, supervisor's model will be used",
            "id": "worker_1-input-model-BaseChatModel"
          }
        ],
        "inputs": {
          "workerName": "Weather",
          "workerPrompt": "You are a weather meteorologist. You return the weather and temperature of a specific location asked",
          "tools": "",
          "supervisor": "{{supervisor_0.data.instance}}",
          "model": "",
          "promptValues": "",
          "maxIterations": ""
        },
        "outputAnchors": [
          {
            "id": "worker_1-output-worker-Worker",
            "name": "worker",
            "label": "Worker",
            "description": "",
            "type": "Worker"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 808,
      "selected": false,
      "positionAbsolute": {
        "x": 224.37483485842378,
        "y": 410.7461926048213
      },
      "dragging": false
    },
    {
      "id": "worker_2",
      "position": {
        "x": 950.9501164522412,
        "y": 8.959058206105965
      },
      "type": "customNode",
      "data": {
        "id": "worker_2",
        "label": "Worker",
        "version": 1,
        "name": "worker",
        "type": "Worker",
        "baseClasses": [
          "Worker"
        ],
        "category": "Multi Agents",
        "inputParams": [
          {
            "label": "Worker Name",
            "name": "workerName",
            "type": "string",
            "placeholder": "Worker",
            "id": "worker_2-input-workerName-string"
          },
          {
            "label": "Worker Prompt",
            "name": "workerPrompt",
            "type": "string",
            "rows": 4,
            "default": "You are a research assistant who can search for up-to-date info using search engine.",
            "id": "worker_2-input-workerPrompt-string"
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "worker_2-input-promptValues-json"
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "id": "worker_2-input-maxIterations-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "optional": true,
            "id": "worker_2-input-tools-Tool"
          },
          {
            "label": "Supervisor",
            "name": "supervisor",
            "type": "Supervisor",
            "id": "worker_2-input-supervisor-Supervisor"
          },
          {
            "label": "Tool Calling Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "optional": true,
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat. If not specified, supervisor's model will be used",
            "id": "worker_2-input-model-BaseChatModel"
          }
        ],
        "inputs": {
          "workerName": "Calculator",
          "workerPrompt": "You are a mathematician. You solve math related problems and provide solutions.",
          "tools": [
            "{{calculator_0.data.instance}}"
          ],
          "supervisor": "{{supervisor_0.data.instance}}",
          "model": "",
          "promptValues": "",
          "maxIterations": ""
        },
        "outputAnchors": [
          {
            "id": "worker_2-output-worker-Worker",
            "name": "worker",
            "label": "Worker",
            "description": "",
            "type": "Worker"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 808,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 950.9501164522412,
        "y": 8.959058206105965
      }
    },
    {
      "id": "calculator_0",
      "position": {
        "x": 1281.6719176305248,
        "y": 34.692558568371595
      },
      "type": "customNode",
      "data": {
        "id": "calculator_0",
        "label": "Calculator",
        "version": 1,
        "name": "calculator",
        "type": "Calculator",
        "baseClasses": [
          "Calculator",
          "Tool",
          "StructuredTool",
          "Runnable"
        ],
        "category": "Tools",
        "description": "Perform calculations on response",
        "inputParams": [],
        "inputAnchors": [],
        "inputs": {},
        "outputAnchors": [
          {
            "id": "calculator_0-output-calculator-Calculator|Tool|StructuredTool|Runnable",
            "name": "calculator",
            "label": "Calculator",
            "description": "Perform calculations on response",
            "type": "Calculator | Tool | StructuredTool | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 143,
      "selected": false,
      "positionAbsolute": {
        "x": 1281.6719176305248,
        "y": 34.692558568371595
      },
      "dragging": false
    },
    {
      "id": "worker_3",
      "position": {
        "x": -482.91497353350627,
        "y": 38.17077565249011
      },
      "type": "customNode",
      "data": {
        "id": "worker_3",
        "label": "Worker",
        "version": 1,
        "name": "worker",
        "type": "Worker",
        "baseClasses": [
          "Worker"
        ],
        "category": "Multi Agents",
        "inputParams": [
          {
            "label": "Worker Name",
            "name": "workerName",
            "type": "string",
            "placeholder": "Worker",
            "id": "worker_3-input-workerName-string"
          },
          {
            "label": "Worker Prompt",
            "name": "workerPrompt",
            "type": "string",
            "rows": 4,
            "default": "You are a research assistant who can search for up-to-date info using search engine.",
            "id": "worker_3-input-workerPrompt-string"
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "worker_3-input-promptValues-json"
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "id": "worker_3-input-maxIterations-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "optional": true,
            "id": "worker_3-input-tools-Tool"
          },
          {
            "label": "Supervisor",
            "name": "supervisor",
            "type": "Supervisor",
            "id": "worker_3-input-supervisor-Supervisor"
          },
          {
            "label": "Tool Calling Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "optional": true,
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat. If not specified, supervisor's model will be used",
            "id": "worker_3-input-model-BaseChatModel"
          }
        ],
        "inputs": {
          "workerName": "Wikipedia",
          "workerPrompt": "You are a research assistant who can search for up-to-date info using search engine.",
          "tools": "",
          "supervisor": "{{supervisor_0.data.instance}}",
          "model": "",
          "promptValues": "",
          "maxIterations": ""
        },
        "outputAnchors": [
          {
            "id": "worker_3-output-worker-Worker",
            "name": "worker",
            "label": "Worker",
            "description": "",
            "type": "Worker"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 808,
      "selected": false,
      "positionAbsolute": {
        "x": -482.91497353350627,
        "y": 38.17077565249011
      },
      "dragging": false
    },
    {
      "id": "worker_4",
      "position": {
        "x": 1299.8776069839864,
        "y": 233.4115192352839
      },
      "type": "customNode",
      "data": {
        "id": "worker_4",
        "label": "Worker",
        "version": 1,
        "name": "worker",
        "type": "Worker",
        "baseClasses": [
          "Worker"
        ],
        "category": "Multi Agents",
        "inputParams": [
          {
            "label": "Worker Name",
            "name": "workerName",
            "type": "string",
            "placeholder": "Worker",
            "id": "worker_4-input-workerName-string"
          },
          {
            "label": "Worker Prompt",
            "name": "workerPrompt",
            "type": "string",
            "rows": 4,
            "default": "You are a research assistant who can search for up-to-date info using search engine.",
            "id": "worker_4-input-workerPrompt-string"
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "worker_4-input-promptValues-json"
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "id": "worker_4-input-maxIterations-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "optional": true,
            "id": "worker_4-input-tools-Tool"
          },
          {
            "label": "Supervisor",
            "name": "supervisor",
            "type": "Supervisor",
            "id": "worker_4-input-supervisor-Supervisor"
          },
          {
            "label": "Tool Calling Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "optional": true,
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat. If not specified, supervisor's model will be used",
            "id": "worker_4-input-model-BaseChatModel"
          }
        ],
        "inputs": {
          "workerName": "News",
          "workerPrompt": "You are a news reporter. You give the latest news articles related to a given query.",
          "tools": "",
          "supervisor": "{{supervisor_0.data.instance}}",
          "model": "",
          "promptValues": "",
          "maxIterations": ""
        },
        "outputAnchors": [
          {
            "id": "worker_4-output-worker-Worker",
            "name": "worker",
            "label": "Worker",
            "description": "",
            "type": "Worker"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 808,
      "selected": false,
      "positionAbsolute": {
        "x": 1299.8776069839864,
        "y": 233.4115192352839
      },
      "dragging": false
    },
    {
      "id": "sqlDatabaseChain_0",
      "position": {
        "x": 1702.3546184870982,
        "y": 73.57276853465623
      },
      "type": "customNode",
      "data": {
        "id": "sqlDatabaseChain_0",
        "label": "Sql Database Chain",
        "version": 5,
        "name": "sqlDatabaseChain",
        "type": "SqlDatabaseChain",
        "baseClasses": [
          "SqlDatabaseChain",
          "BaseChain",
          "Runnable"
        ],
        "category": "Chains",
        "description": "Answer questions over a SQL database",
        "inputParams": [
          {
            "label": "Database",
            "name": "database",
            "type": "options",
            "options": [
              {
                "label": "SQLite",
                "name": "sqlite"
              },
              {
                "label": "PostgreSQL",
                "name": "postgres"
              },
              {
                "label": "MSSQL",
                "name": "mssql"
              },
              {
                "label": "MySQL",
                "name": "mysql"
              }
            ],
            "default": "sqlite",
            "id": "sqlDatabaseChain_0-input-database-options"
          },
          {
            "label": "Connection string or file path (sqlite only)",
            "name": "url",
            "type": "string",
            "placeholder": "1270.0.0.1:5432/chinook",
            "id": "sqlDatabaseChain_0-input-url-string"
          },
          {
            "label": "Include Tables",
            "name": "includesTables",
            "type": "string",
            "description": "Tables to include for queries, separated by comma. Can only use Include Tables or Ignore Tables",
            "placeholder": "table1, table2",
            "additionalParams": true,
            "optional": true,
            "id": "sqlDatabaseChain_0-input-includesTables-string"
          },
          {
            "label": "Ignore Tables",
            "name": "ignoreTables",
            "type": "string",
            "description": "Tables to ignore for queries, separated by comma. Can only use Ignore Tables or Include Tables",
            "placeholder": "table1, table2",
            "additionalParams": true,
            "optional": true,
            "id": "sqlDatabaseChain_0-input-ignoreTables-string"
          },
          {
            "label": "Sample table's rows info",
            "name": "sampleRowsInTableInfo",
            "type": "number",
            "description": "Number of sample row for tables to load for info.",
            "placeholder": "3",
            "additionalParams": true,
            "optional": true,
            "id": "sqlDatabaseChain_0-input-sampleRowsInTableInfo-number"
          },
          {
            "label": "Top Keys",
            "name": "topK",
            "type": "number",
            "description": "If you are querying for several rows of a table you can select the maximum number of results you want to get by using the \"top_k\" parameter (default is 10). This is useful for avoiding query results that exceed the prompt max length or consume tokens unnecessarily.",
            "placeholder": "10",
            "additionalParams": true,
            "optional": true,
            "id": "sqlDatabaseChain_0-input-topK-number"
          },
          {
            "label": "Custom Prompt",
            "name": "customPrompt",
            "type": "string",
            "description": "You can provide custom prompt to the chain. This will override the existing default prompt used. See <a target=\"_blank\" href=\"https://python.langchain.com/docs/integrations/tools/sqlite#customize-prompt\">guide</a>",
            "warning": "Prompt must include 3 input variables: {input}, {dialect}, {table_info}. You can refer to official guide from description above",
            "rows": 4,
            "placeholder": "Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer. Unless the user specifies in his question a specific number of examples he wishes to obtain, always limit your query to at most {top_k} results. You can order the results by a relevant column to return the most interesting examples in the database.\n\nNever query for all the columns from a specific table, only ask for a the few relevant columns given the question.\n\nPay attention to use only the column names that you can see in the schema description. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n\nUse the following format:\n\nQuestion: \"Question here\"\nSQLQuery: \"SQL Query to run\"\nSQLResult: \"Result of the SQLQuery\"\nAnswer: \"Final answer here\"\n\nOnly use the tables listed below.\n\n{table_info}\n\nQuestion: {input}f-string",
            "additionalParams": true,
            "optional": true,
            "id": "sqlDatabaseChain_0-input-customPrompt-string"
          }
        ],
        "inputAnchors": [
          {
            "label": "Language Model",
            "name": "model",
            "type": "BaseLanguageModel",
            "id": "sqlDatabaseChain_0-input-model-BaseLanguageModel"
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "sqlDatabaseChain_0-input-inputModeration-Moderation"
          }
        ],
        "inputs": {
          "model": "{{chatOpenAI_0.data.instance}}",
          "database": "postgres",
          "url": "",
          "includesTables": "",
          "ignoreTables": "",
          "sampleRowsInTableInfo": "",
          "topK": "",
          "customPrompt": "",
          "inputModeration": ""
        },
        "outputAnchors": [
          {
            "id": "sqlDatabaseChain_0-output-sqlDatabaseChain-SqlDatabaseChain|BaseChain|Runnable",
            "name": "sqlDatabaseChain",
            "label": "SqlDatabaseChain",
            "description": "Answer questions over a SQL database",
            "type": "SqlDatabaseChain | BaseChain | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 527,
      "selected": false,
      "positionAbsolute": {
        "x": 1702.3546184870982,
        "y": 73.57276853465623
      },
      "dragging": false
    }
  ],
  "edges": [
    {
      "source": "chatOpenAI_0",
      "sourceHandle": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "supervisor_0",
      "targetHandle": "supervisor_0-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "chatOpenAI_0-chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-supervisor_0-supervisor_0-input-model-BaseChatModel"
    },
    {
      "source": "supervisor_0",
      "sourceHandle": "supervisor_0-output-supervisor-Supervisor",
      "target": "worker_0",
      "targetHandle": "worker_0-input-supervisor-Supervisor",
      "type": "buttonedge",
      "id": "supervisor_0-supervisor_0-output-supervisor-Supervisor-worker_0-worker_0-input-supervisor-Supervisor"
    },
    {
      "source": "supervisor_0",
      "sourceHandle": "supervisor_0-output-supervisor-Supervisor",
      "target": "worker_1",
      "targetHandle": "worker_1-input-supervisor-Supervisor",
      "type": "buttonedge",
      "id": "supervisor_0-supervisor_0-output-supervisor-Supervisor-worker_1-worker_1-input-supervisor-Supervisor"
    },
    {
      "source": "calculator_0",
      "sourceHandle": "calculator_0-output-calculator-Calculator|Tool|StructuredTool|Runnable",
      "target": "worker_2",
      "targetHandle": "worker_2-input-tools-Tool",
      "type": "buttonedge",
      "id": "calculator_0-calculator_0-output-calculator-Calculator|Tool|StructuredTool|Runnable-worker_2-worker_2-input-tools-Tool"
    },
    {
      "source": "supervisor_0",
      "sourceHandle": "supervisor_0-output-supervisor-Supervisor",
      "target": "worker_3",
      "targetHandle": "worker_3-input-supervisor-Supervisor",
      "type": "buttonedge",
      "id": "supervisor_0-supervisor_0-output-supervisor-Supervisor-worker_3-worker_3-input-supervisor-Supervisor"
    },
    {
      "source": "supervisor_0",
      "sourceHandle": "supervisor_0-output-supervisor-Supervisor",
      "target": "worker_2",
      "targetHandle": "worker_2-input-supervisor-Supervisor",
      "type": "buttonedge",
      "id": "supervisor_0-supervisor_0-output-supervisor-Supervisor-worker_2-worker_2-input-supervisor-Supervisor"
    },
    {
      "source": "supervisor_0",
      "sourceHandle": "supervisor_0-output-supervisor-Supervisor",
      "target": "worker_4",
      "targetHandle": "worker_4-input-supervisor-Supervisor",
      "type": "buttonedge",
      "id": "supervisor_0-supervisor_0-output-supervisor-Supervisor-worker_4-worker_4-input-supervisor-Supervisor"
    },
    {
      "source": "chatOpenAI_0",
      "sourceHandle": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "sqlDatabaseChain_0",
      "targetHandle": "sqlDatabaseChain_0-input-model-BaseLanguageModel",
      "type": "buttonedge",
      "id": "chatOpenAI_0-chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-sqlDatabaseChain_0-sqlDatabaseChain_0-input-model-BaseLanguageModel"
    }
  ]
}